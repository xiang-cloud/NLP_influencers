# NLP Influencers Network Analysis ğŸŒ

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![YouTube](https://img.shields.io/badge/YouTube-API-red.svg)](https://developers.google.com/youtube/v3)
[![Pandas](https://img.shields.io/badge/Pandas-2.1.3-150458.svg)](https://pandas.pydata.org/)
[![Spacy](https://img.shields.io/badge/SpaCy-3.7.2-09A3D5.svg)](https://spacy.io/)
[![NLTK](https://img.shields.io/badge/NLTK-3.8.1-147814.svg)](https://www.nltk.org/)
[![Gensim](https://img.shields.io/badge/Gensim-4.3.2-FF6F61.svg)](https://radimrehurek.com/gensim/)
[![Flair](https://img.shields.io/badge/Flair-0.13.0-orange.svg)](https://github.com/flairNLP/flair)
[![NetworkX](https://img.shields.io/badge/NetworkX-3.2.1-yellow.svg)](https://networkx.org/)
[![Plotly](https://img.shields.io/badge/Plotly-5.18.0-3F4F75.svg)](https://plotly.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.2-F7931E.svg)](https://scikit-learn.org/)

Analyze YouTube influencer networks and content using NLP techniques. Extract video data, analyze relationships, and generate insights from Spanish-speaking influencers' content. ğŸ¥ ğŸ‘¥

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone [repository-url]
cd NLP_influencers

# Install dependencies
pip install -r requirements.txt

# Set up YouTube API
# 1. Get API key from Google Cloud Console
# 2. Replace API_KEY in ETL_video_1.py and Comments_extraction.py

# Run data collection
python ETL_video_1.py
python Comments_extraction.py
```

## ğŸ“‹ Overview

This project analyzes Spanish-speaking YouTube influencers through:
- ğŸ” Content analysis using NLP
- ğŸ•¸ï¸ Network relationship mapping
- ğŸ“Š Engagement metrics analysis
- ğŸ‘¥ Named Entity Recognition for person mentions
- ğŸ“ˆ Interactive visualizations

## Project Structure

```
.
â”œâ”€â”€ Data Collection Scripts
â”‚   â”œâ”€â”€ ETL_video_1.py              # Video metadata and transcript extraction
â”‚   â””â”€â”€ Comments_extraction.py       # Comments data extraction
â”‚
â”œâ”€â”€ Network Analysis
â”‚   â”œâ”€â”€ network_influencers.ipynb    # Cross-influencer network analysis
â”‚   â”œâ”€â”€ network.html                 # Basic network visualization
â”‚   â””â”€â”€ enhanced_network.html        # Enhanced network with metrics
â”‚
â”œâ”€â”€ Influencer Folders               # Individual analysis per influencer
â”‚   â”œâ”€â”€ [influencer]/               # Repeated for each influencer below
â”‚   â”‚   â”œâ”€â”€ Data/
â”‚   â”‚   â”‚   â”œâ”€â”€ [influencer]_videos.csv     # Raw video data
â”‚   â”‚   â”‚   â”œâ”€â”€ [influencer]_comments.csv   # Raw comments
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessed_data.csv       # Cleaned text data
â”‚   â”‚   â”‚   â”œâ”€â”€ refined_per_data.csv        # Processed mentions
â”‚   â”‚   â”‚   â”œâ”€â”€ PER_filtered_data.csv       # Filtered entities
â”‚   â”‚   â”‚   â””â”€â”€ PER2_token.csv             # Tokenized mentions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ EDA_[influencer].ipynb      # Exploratory analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing_text.ipynb     # Text preprocessing
â”‚   â”‚   â”‚   â”œâ”€â”€ transcript_NLP_test.ipynb    # NLP analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ transcript_NLP_lemma.ipynb   # Lemmatization
â”‚   â”‚   â”‚   â”œâ”€â”€ network.ipynb               # Network analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ PER.ipynb                   # Entity recognition
â”‚   â”‚   â”‚   â”œâ”€â”€ per_clean.ipynb             # Entity cleaning
â”‚   â”‚   â”‚   â””â”€â”€ horastrabajo.ipynb          # Work hours analysis
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Visualizations/
â”‚   â”‚       â”œâ”€â”€ Network/
â”‚   â”‚       â”‚   â”œâ”€â”€ network.html            # Basic network
â”‚   â”‚       â”‚   â””â”€â”€ network_preprocessed.html # Processed network
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ WordClouds/
â”‚   â”‚           â”œâ”€â”€ title_wordcloud.png      # Title analysis
â”‚   â”‚           â”œâ”€â”€ description_wordcloud.png # Description analysis
â”‚   â”‚           â”œâ”€â”€ transcript_wordcloud.png  # Transcript analysis
â”‚   â”‚           â”œâ”€â”€ *_preprocessed.png       # Processed versions
â”‚   â”‚           â””â”€â”€ all_words.png            # Combined analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ auronplay/                  # Spanish streamer
â”‚   â”œâ”€â”€ ElRubius/                   # Gaming content creator
â”‚   â”œâ”€â”€ Ibai/                       # Sports and entertainment
â”‚   â”œâ”€â”€ Vegetta/                    # Gaming content
â”‚   â”œâ”€â”€ DjMario/                    # Music and gaming
â”‚   â”œâ”€â”€ Orslok/                     # Variety content
â”‚   â”œâ”€â”€ Mostopapi/                  # Entertainment
â”‚   â”œâ”€â”€ MartaDiaz/                  # Lifestyle content
â”‚   â”œâ”€â”€ Malbert/                    # Comedy content
â”‚   â”œâ”€â”€ EmmaChamberlain/            # English content (comparison)
â”‚   â””â”€â”€ clakovi/                    # Gaming content
â”‚
â”œâ”€â”€ lib/                            # Shared utilities and functions
â”‚   â””â”€â”€ [shared python modules]
â”‚
â”œâ”€â”€ requirements.txt                # Project dependencies
â””â”€â”€ memoria_TFM_versionfinal.pdf    # Detailed project documentation
```

## ğŸ”„ Analysis Pipeline

1. **Data Collection & ETL** ğŸ“¥
   - Extract video metadata using YouTube API (`ETL_video_1.py`)
     - Video titles, descriptions, statistics
     - View counts, likes, comments
     - Video transcripts (when available)
   - Collect comments data (`Comments_extraction.py`)
     - Comment text and metadata
     - Comment statistics
     - User interaction data

2. **Exploratory Data Analysis** ğŸ“Š
   - Per-influencer analysis (`EDA_[influencer].ipynb`)
     - Posting patterns and frequency
     - Engagement metrics analysis
     - Content type distribution
     - Temporal trends
   - Data quality assessment
     - Missing data handling
     - Outlier detection
     - Data validation

3. **Text Processing & NLP** ğŸ“
   - Text preprocessing (`preprocessing_text.ipynb`)
     - Tokenization and normalization
     - Stop word removal
     - Special character handling
     - Language detection and filtering
   - Named Entity Recognition (`PER.ipynb`)
     - Person name extraction
     - Entity standardization (`per_clean.ipynb`)
     - Name variant mapping
   - Content Analysis
     - Word frequency analysis
     - Topic extraction
     - Keyword identification
     - Word cloud generation

4. **Network Analysis** ğŸ•¸ï¸
   - Individual Network Analysis (`network.ipynb`)
     - Per-influencer connection mapping
     - Local community detection
     - Influence metrics calculation
   - Cross-influencer Analysis (`network_influencers.ipynb`)
     - Relationship network construction
     - Community detection
     - Centrality analysis
     - Influence flow mapping

5. **Visualization & Reporting** ğŸ“Š
   - Network Visualizations
     - Basic network graphs (`network.html`)
     - Enhanced network visualization (`enhanced_network.html`)
     - Interactive network exploration
   - Content Insights
     - Word clouds for different text fields
     - Temporal pattern visualizations
     - Engagement metric charts
   - Final Analysis
     - Key findings documentation
     - Pattern identification
     - Insight generation

## â­ Key Features

- **Content Analysis** ğŸ“
  - Multi-language support (ES/EN)
  - Topic modeling
  - Person mention detection
  - Temporal patterns

- **Network Analysis** ğŸ•¸ï¸
  - Relationship mapping
  - Community detection
  - Influence measurement

- **Visualization** ğŸ“Š
  - Interactive networks
  - Word clouds
  - Engagement metrics

## ğŸ› ï¸ Requirements

See `requirements.txt` for full list of dependencies.

Main requirements:
- Python 3.8+ ğŸ
- YouTube Data API credentials ğŸ”‘
- 2GB+ RAM for NLP processing ğŸ’»

Key Dependencies:
- **Core**: `numpy`, `pandas`, `jupyter`
- **NLP**: `spacy`, `flair`, `nltk`, `gensim`
  - Spanish language model: `es_core_news_lg`
  - English language model: `en_core_web_lg`
  - NLTK data packages: `punkt`, `stopwords`, `wordnet`, `averaged_perceptron_tagger`
- **Network**: `networkx`
- **Visualization**: `matplotlib`, `seaborn`, `plotly`, `wordcloud`
- **ML**: `scikit-learn`

## ğŸ“ Data Files

- **Input** ğŸ“¥
  - YouTube API credentials
  - List of influencer channels

- **Output** ğŸ“¤
  - **Raw Data**
    - `[influencer]_videos.csv`: Video metadata
    - `[influencer]_comments.csv`: Comment data
  
  - **Processed Data**
    - `refined_per_data.csv`: Processed person mentions
    - `preprocessed_data.csv`: Cleaned text data
    - `PER_filtered_data.csv`: Filtered person entities
    - `PER2_token.csv`: Tokenized person mentions

  - **Network Visualizations**
    - `network.html`: Basic network graph
    - `enhanced_network.html`: Detailed network visualization
    - `network_preprocessed.html`: Network with preprocessed data

  - **Word Clouds**
    - `title_wordcloud.png`: Most frequent words in video titles
    - `description_wordcloud.png`: Key terms from video descriptions
    - `transcript_wordcloud.png`: Common words from video transcripts
    - `*_preprocessed.png`: Processed versions
    - `all_words.png`: Combined analysis

## ğŸ“ Notes

- â° Data collection configured until April 1, 2023
- ğŸ‡ªğŸ‡¸ Optimized for Spanish content analysis
- âš¡ Handles API rate limits automatically
- ğŸš€ Parallel processing support

## ğŸ¤ Contributing

1. Fork the repository ğŸ´
2. Create a feature branch ğŸŒ¿
3. Submit a pull request ğŸ¯

## ğŸ“„ License

MIT License

Copyright (c) 2024 NLP Influencers Project

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE. 